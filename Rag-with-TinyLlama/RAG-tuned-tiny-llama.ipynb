{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8023561",
   "metadata": {},
   "source": [
    "Original youtube video\"https://www.youtube.com/watch?v=mfm14MRcnz0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4893a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: txtai[pipeline] in ./miniconda3/lib/python3.10/site-packages (6.3.0)\n",
      "Requirement already satisfied: faiss-cpu>=1.7.1.post2 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (1.7.4)\n",
      "Requirement already satisfied: torch>=1.12.1 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (2.0.0)\n",
      "Requirement already satisfied: transformers>=4.22.0 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (4.33.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.9.0 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.18.4 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (1.24.3)\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (6.0.1)\n",
      "Requirement already satisfied: regex>=2022.8.17 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (2023.10.3)\n",
      "Collecting onnx>=1.11.0 (from txtai[pipeline])\n",
      "  Downloading onnx-1.15.0-cp310-cp310-macosx_10_12_universal2.whl.metadata (15 kB)\n",
      "Collecting onnxruntime>=1.11.0 (from txtai[pipeline])\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.3 kB)\n",
      "Collecting soundfile>=0.10.3.post1 (from txtai[pipeline])\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (1.10.1)\n",
      "Collecting ttstokenizer>=1.0.0 (from txtai[pipeline])\n",
      "  Downloading ttstokenizer-1.0.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.9.3 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (4.12.2)\n",
      "Requirement already satisfied: nltk>=3.5 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (3.8.1)\n",
      "Requirement already satisfied: pandas>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (2.0.1)\n",
      "Collecting tika>=1.24 (from txtai[pipeline])\n",
      "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting imagehash>=4.2.1 (from txtai[pipeline])\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (10.0.1)\n",
      "Collecting timm>=0.4.12 (from txtai[pipeline])\n",
      "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting litellm>=1.15.8 (from txtai[pipeline])\n",
      "  Downloading litellm-1.18.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-cpp-python>=0.2.20 (from txtai[pipeline])\n",
      "  Downloading llama_cpp_python-0.2.29.tar.gz (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fasttext>=0.9.2 (from txtai[pipeline])\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.91 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (0.1.99)\n",
      "Requirement already satisfied: accelerate>=0.19.0 in ./miniconda3/lib/python3.10/site-packages (from txtai[pipeline]) (0.25.0)\n",
      "Collecting onnxmltools>=1.9.1 (from txtai[pipeline])\n",
      "  Downloading onnxmltools-1.12.0-py2.py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting skl2onnx>=1.9.1 (from txtai[pipeline])\n",
      "  Downloading skl2onnx-1.16.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.10/site-packages (from accelerate>=0.19.0->txtai[pipeline]) (23.1)\n",
      "Requirement already satisfied: psutil in ./miniconda3/lib/python3.10/site-packages (from accelerate>=0.19.0->txtai[pipeline]) (5.9.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniconda3/lib/python3.10/site-packages (from accelerate>=0.19.0->txtai[pipeline]) (0.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./miniconda3/lib/python3.10/site-packages (from beautifulsoup4>=4.9.3->txtai[pipeline]) (2.5)\n",
      "Collecting pybind11>=2.2 (from fasttext>=0.9.2->txtai[pipeline])\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in ./miniconda3/lib/python3.10/site-packages (from fasttext>=0.9.2->txtai[pipeline]) (65.6.3)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai[pipeline]) (3.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai[pipeline]) (2023.10.0)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai[pipeline]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai[pipeline]) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai[pipeline]) (4.9.0)\n",
      "Collecting PyWavelets (from imagehash>=4.2.1->txtai[pipeline])\n",
      "  Downloading pywavelets-1.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: aiohttp in ./miniconda3/lib/python3.10/site-packages (from litellm>=1.15.8->txtai[pipeline]) (3.9.0)\n",
      "Requirement already satisfied: click in ./miniconda3/lib/python3.10/site-packages (from litellm>=1.15.8->txtai[pipeline]) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in ./miniconda3/lib/python3.10/site-packages (from litellm>=1.15.8->txtai[pipeline]) (7.0.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in ./miniconda3/lib/python3.10/site-packages (from litellm>=1.15.8->txtai[pipeline]) (3.1.2)\n",
      "Requirement already satisfied: openai>=1.0.0 in ./miniconda3/lib/python3.10/site-packages (from litellm>=1.15.8->txtai[pipeline]) (1.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in ./miniconda3/lib/python3.10/site-packages (from litellm>=1.15.8->txtai[pipeline]) (1.0.0)\n",
      "Collecting tiktoken>=0.4.0 (from litellm>=1.15.8->txtai[pipeline])\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tokenizers in ./miniconda3/lib/python3.10/site-packages (from litellm>=1.15.8->txtai[pipeline]) (0.13.3)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in ./miniconda3/lib/python3.10/site-packages (from llama-cpp-python>=0.2.20->txtai[pipeline]) (5.6.3)\n",
      "Requirement already satisfied: joblib in ./miniconda3/lib/python3.10/site-packages (from nltk>=3.5->txtai[pipeline]) (1.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./miniconda3/lib/python3.10/site-packages (from onnx>=1.11.0->txtai[pipeline]) (3.20.3)\n",
      "Collecting coloredlogs (from onnxruntime>=1.11.0->txtai[pipeline])\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in ./miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.11.0->txtai[pipeline]) (1.12)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.11.0->txtai[pipeline]) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/lib/python3.10/site-packages (from pandas>=1.1.0->txtai[pipeline]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.10/site-packages (from pandas>=1.1.0->txtai[pipeline]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./miniconda3/lib/python3.10/site-packages (from pandas>=1.1.0->txtai[pipeline]) (2023.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in ./miniconda3/lib/python3.10/site-packages (from skl2onnx>=1.9.1->txtai[pipeline]) (1.2.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxconverter-common>=1.7.0 (from skl2onnx>=1.9.1->txtai[pipeline])\n",
      "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in ./miniconda3/lib/python3.10/site-packages (from soundfile>=0.10.3.post1->txtai[pipeline]) (1.16.0)\n",
      "Requirement already satisfied: torchvision in ./miniconda3/lib/python3.10/site-packages (from timm>=0.4.12->txtai[pipeline]) (0.15.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch>=1.12.1->txtai[pipeline]) (3.1)\n",
      "Collecting anyascii>=0.3.1 (from ttstokenizer>=1.0.0->txtai[pipeline])\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting inflect>=0.3.1 (from ttstokenizer>=1.0.0->txtai[pipeline])\n",
      "  Downloading inflect-7.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pycparser in ./miniconda3/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.3.post1->txtai[pipeline]) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in ./miniconda3/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm>=1.15.8->txtai[pipeline]) (3.17.0)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in ./miniconda3/lib/python3.10/site-packages (from inflect>=0.3.1->ttstokenizer>=1.0.0->txtai[pipeline]) (2.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.15.8->txtai[pipeline]) (2.1.2)\n",
      "Collecting protobuf>=3.20.2 (from onnx>=1.11.0->txtai[pipeline])\n",
      "  Downloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in ./miniconda3/lib/python3.10/site-packages (from openai>=1.0.0->litellm>=1.15.8->txtai[pipeline]) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./miniconda3/lib/python3.10/site-packages (from openai>=1.0.0->litellm>=1.15.8->txtai[pipeline]) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./miniconda3/lib/python3.10/site-packages (from openai>=1.0.0->litellm>=1.15.8->txtai[pipeline]) (0.26.0)\n",
      "Requirement already satisfied: sniffio in ./miniconda3/lib/python3.10/site-packages (from openai>=1.0.0->litellm>=1.15.8->txtai[pipeline]) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.0->txtai[pipeline]) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai[pipeline]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai[pipeline]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai[pipeline]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai[pipeline]) (2023.11.17)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./miniconda3/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx>=1.9.1->txtai[pipeline]) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->litellm>=1.15.8->txtai[pipeline]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->litellm>=1.15.8->txtai[pipeline]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->litellm>=1.15.8->txtai[pipeline]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->litellm>=1.15.8->txtai[pipeline]) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->litellm>=1.15.8->txtai[pipeline]) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->litellm>=1.15.8->txtai[pipeline]) (4.0.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.11.0->txtai[pipeline])\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in ./miniconda3/lib/python3.10/site-packages (from sympy->onnxruntime>=1.11.0->txtai[pipeline]) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->litellm>=1.15.8->txtai[pipeline]) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->litellm>=1.15.8->txtai[pipeline]) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./miniconda3/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect>=0.3.1->ttstokenizer>=1.0.0->txtai[pipeline]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in ./miniconda3/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect>=0.3.1->ttstokenizer>=1.0.0->txtai[pipeline]) (2.14.6)\n",
      "Downloading litellm-1.18.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.15.0-cp310-cp310-macosx_10_12_universal2.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxmltools-1.12.0-py2.py3-none-any.whl (329 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.16.3-cp310-cp310-macosx_11_0_arm64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading skl2onnx-1.16.0-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.5/298.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading inflect-7.0.0-py3-none-any.whl (34 kB)\n",
      "Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "Downloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pywavelets-1.5.0-cp310-cp310-macosx_11_0_arm64.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fasttext, llama-cpp-python, tika\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-macosx_14_0_arm64.whl size=276237 sha256=826e9b0f65519701af5d043e0503cfae42ea05d814edfd737a533f13b7013048\n",
      "  Stored in directory: /Users/arnabsom/Library/Caches/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.29-cp310-cp310-macosx_14_0_arm64.whl size=2284494 sha256=9e4c0da6a5b628a32b2770ff96cbe0efdc6b57abe96d59b80887e6d6da967f36\n",
      "  Stored in directory: /Users/arnabsom/Library/Caches/pip/wheels/aa/09/8d/df365429984babf5a986216d50a8c5d465c4772399e2902397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for tika (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32625 sha256=a7df0f4af5048d3cb5fe2c55df40226ed0ad29ce98fd116169df6d5e3951515b\n",
      "  Stored in directory: /Users/arnabsom/Library/Caches/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
      "Successfully built fasttext llama-cpp-python tika\n",
      "Installing collected packages: PyWavelets, pybind11, protobuf, llama-cpp-python, humanfriendly, anyascii, tiktoken, tika, soundfile, onnx, imagehash, fasttext, coloredlogs, onnxruntime, onnxmltools, onnxconverter-common, inflect, ttstokenizer, timm, skl2onnx, litellm\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: llama-cpp-python\n",
      "    Found existing installation: llama_cpp_python 0.1.78\n",
      "    Uninstalling llama_cpp_python-0.1.78:\n",
      "      Successfully uninstalled llama_cpp_python-0.1.78\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.3.3\n",
      "    Uninstalling tiktoken-0.3.3:\n",
      "      Successfully uninstalled tiktoken-0.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-datasets 4.9.2 requires toml, which is not installed.\n",
      "openai-whisper 20230314 requires tiktoken==0.3.3, but you have tiktoken 0.5.2 which is incompatible.\n",
      "tensorflow-macos 2.9.0 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.15.1 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyWavelets-1.5.0 anyascii-0.3.2 coloredlogs-15.0.1 fasttext-0.9.2 humanfriendly-10.0 imagehash-4.3.1 inflect-7.0.0 litellm-1.18.1 llama-cpp-python-0.2.29 onnx-1.15.0 onnxconverter-common-1.14.0 onnxmltools-1.12.0 onnxruntime-1.16.3 protobuf-3.20.2 pybind11-2.11.1 skl2onnx-1.16.0 soundfile-0.12.1 tika-2.6.0 tiktoken-0.5.2 timm-0.9.12 ttstokenizer-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install txtai[pipeline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e805747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python==0.1.78\n",
      "  Using cached llama_cpp_python-0.1.78-cp310-cp310-macosx_14_0_arm64.whl\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./miniconda3/lib/python3.10/site-packages (from llama-cpp-python==0.1.78) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./miniconda3/lib/python3.10/site-packages (from llama-cpp-python==0.1.78) (1.24.3)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in ./miniconda3/lib/python3.10/site-packages (from llama-cpp-python==0.1.78) (5.6.3)\n",
      "Installing collected packages: llama-cpp-python\n",
      "  Attempting uninstall: llama-cpp-python\n",
      "    Found existing installation: llama_cpp_python 0.2.29\n",
      "    Uninstalling llama_cpp_python-0.2.29:\n",
      "      Successfully uninstalled llama_cpp_python-0.2.29\n",
      "Successfully installed llama-cpp-python-0.1.78\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-cpp-python==0.1.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f125d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3f4aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/arnabsom/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f4af39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from txtai.pipeline import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a41d85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a06db57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>\\nwhat is coral bleach?'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"\"\"<|im_start|>user\n",
    "what is coral bleach? \n",
    "<|im_end|><|im_start|>assistant\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c14223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from txtai.pipeline import Textractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8c5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "textractor = Textractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ada1b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: txtai in ./miniconda3/lib/python3.10/site-packages (6.3.0)\n",
      "Requirement already satisfied: faiss-cpu>=1.7.1.post2 in ./miniconda3/lib/python3.10/site-packages (from txtai) (1.7.4)\n",
      "Requirement already satisfied: torch>=1.12.1 in ./miniconda3/lib/python3.10/site-packages (from txtai) (2.0.0)\n",
      "Requirement already satisfied: transformers>=4.22.0 in ./miniconda3/lib/python3.10/site-packages (from txtai) (4.33.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.9.0 in ./miniconda3/lib/python3.10/site-packages (from txtai) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.18.4 in ./miniconda3/lib/python3.10/site-packages (from txtai) (1.24.3)\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./miniconda3/lib/python3.10/site-packages (from txtai) (6.0.1)\n",
      "Requirement already satisfied: regex>=2022.8.17 in ./miniconda3/lib/python3.10/site-packages (from txtai) (2023.10.3)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (3.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (2023.10.0)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (23.1)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.10/site-packages (from torch>=1.12.1->txtai) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch>=1.12.1->txtai) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch>=1.12.1->txtai) (3.1.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./miniconda3/lib/python3.10/site-packages (from transformers>=4.22.0->txtai) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniconda3/lib/python3.10/site-packages (from transformers>=4.22.0->txtai) (0.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->torch>=1.12.1->txtai) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.9.0->txtai) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./miniconda3/lib/python3.10/site-packages (from sympy->torch>=1.12.1->txtai) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install txtai --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47e4cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textractor(\"coral.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a78b97b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coral bleaching is a phenomenon where coral reefs lose their vibrant colors due to the expulsion of symbiotic algae called zooxanthellae. These algae live in the tissues of corals and provide them with nutrients through photosynthesis. When coral polyps expel the algae, the coral turns white or pale, hence the term \"bleaching.\"',\n",
       " 'Several factors can trigger coral bleaching, with the primary cause being increased sea temperatures. Elevated water temperatures stress the coral, leading them to expel the algae. Other factors contributing to coral bleaching include pollution, changes in salinity, and extreme weather events.',\n",
       " 'Coral bleaching is a significant concern because it weakens the corals and makes them more susceptible to diseases. If the stressors persist, it can lead to the death of coral reefs, which are vital ecosystems supporting marine biodiversity. Efforts to address climate change, reduce pollution, and protect coral reef habitats are crucial in preventing and mitigating coral bleaching events.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34460706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from txtai.embeddings import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bc2cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(path):\n",
    "    #for f in sorted(os.listdir(path)):\n",
    "    #fpath = os.path.join(path)\n",
    "    #only accepts documents\n",
    "    if path.endswith((\"txt\",\"docx\",\"pdf\")):\n",
    "        print(f\"Indexing {path}\")\n",
    "        for paragraph in textractor(path):\n",
    "            yield paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0266d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "textractor = Textractor(paragraphs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c55af0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings(content=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4101bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing coral.txt\n"
     ]
    }
   ],
   "source": [
    "embeddings.index(stream(\"coral.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33b2fd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<txtai.embeddings.base.Embeddings at 0xae65f9d20>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108649cf",
   "metadata": {},
   "source": [
    "Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fa3ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(question, text):\n",
    "    prompt = f\"\"\"\n",
    "    <|im_start|>user\n",
    "    Answer the following question using only the context below.Only include information specifically discussed.\n",
    "    \n",
    "    question:{question}\n",
    "    context:{text} <|im_end|>\n",
    "    <|im_start|>assistant\n",
    "    \"\"\"\n",
    "    print(prompt)\n",
    "    return llm(prompt) #maxlength=4096, pad_token_id=32000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb1479",
   "metadata": {},
   "source": [
    "joining embeddings with original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5670421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context(question):\n",
    "    context = \"\\n\".join(x[\"text\"] for x in embeddings.search(question))\n",
    "    return context\n",
    "def rag(question):\n",
    "    return execute(question, context(question))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9ed21c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <|im_start|>user\n",
      "    Answer the following question using only the context below.Only include information specifically discussed.\n",
      "    \n",
      "    question:what is coral bleach?\n",
      "    context:Coral bleaching is a phenomenon where coral reefs lose their vibrant colors due to the expulsion of symbiotic algae called zooxanthellae. These algae live in the tissues of corals and provide them with nutrients through photosynthesis. When coral polyps expel the algae, the coral turns white or pale, hence the term \"bleaching.\"\n",
      "Coral bleaching is a significant concern because it weakens the corals and makes them more susceptible to diseases. If the stressors persist, it can lead to the death of coral reefs, which are vital ecosystems supporting marine biodiversity. Efforts to address climate change, reduce pollution, and protect coral reef habitats are crucial in preventing and mitigating coral bleaching events.\n",
      "Several factors can trigger coral bleaching, with the primary cause being increased sea temperatures. Elevated water temperatures stress the coral, leading them to expel the algae. Other factors contributing to coral bleaching include pollution, changes in salinity, and extreme weather events. <|im_end|>\n",
      "    <|im_start|>assistant\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "result = rag(\"what is coral bleach?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce5e5046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|assistant|>\\n    The coral bleach is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is a phenomenon where coral bleach due to the coral bleaching event. The coral bleaching is'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e366834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
